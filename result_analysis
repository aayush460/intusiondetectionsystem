import tensorflow
import pandas as pd
import numpy as np
import os
from time import time
from keras.layers import Dense, Dropout, RNN, LSTM, GRU
from  tensorflow.compat.v1.keras.layers import CuDNNLSTM
from keras import Sequential
from keras.callbacks import TensorBoard, ModelCheckpoint
from sklearn.metrics import (confusion_matrix, roc_auc_score, precision_score, auc)


csv_values = ['epochs', 'acc', 'loss', 'val_acc', 'val_loss', "train_data","features_nb", 'loss_fct', 'optimizer', 'activation_fct',
              'layer_nb', 'unit_nb', 'batch_size', 'dropout', 'cell_type', 'encoder']

csv_best_res = ['param', 'value', 'min_mean_val_loss']


params = {'epochs': 50,  'features_nb': 4,'loss_fct': 'mse','optimizer': 'rmsprop','activation_fct': 'sigmoid', 'layer_nb': 5, 'unit_nb': 128,
          'batch_size': 1024, 'dropout': 0.2, 'cell_type': 'LSTM','encoder': 'ordinalencoder', 'dataset': 'unsw', 'training_nb': 1,
          'resultstocsv': False, 'resultstologs': False, 'showresults': True,'shuffle': True}


params_var = {
              'encoder': ['standardscaler', 'labelencoder', 'minmaxscaler01', 'minmaxscaler11', 'ordinalencoder'],
              'optimizer': ['adam', 'sgd', 'rmsprop', 'nadam', 'adamax','adadelta'],
              'activation_fct': ['sigmoid', 'softmax', 'relu', 'tanh'],
              'layer_nb': [1, 2, 3, 4],
              'unit_nb': [4, 8, 32, 64, 128, 256],
              'dropout': [0.1, 0.2, 0.3, 0.4],
              'batch_size': [512, 1024, 2048],
              'features_nb': [4, 8, 41],
              'train_data': [494021, 4898431, 125973, 25191],
              'cell_type': ['CuDNNLSTM','RNN', 'LSTM', 'GRU'],
              'dataset' : ['kdd', 'unsw']
              }

model_path = 'c:/models'
logs_path = 'c:/logs'
res_path = '.c:/results/'

if params['resultstologs'] is True:
    res_name = str(params['train_data']) + '_' + str(params['features_nb']) +'_' + params['loss_fct'] + '_' + params['optimizer'] + '_' +\
        params['activation_fct'] + '_' + str(params['layer_nb']) + '_' +str(params['unit_nb']) + '_' + str(params['batch_size']) + '_' +\
        str(params['dropout']) + '_' + params['cell_type'] + '_' +params['encoder'] + '_' + str(time())


def load_data():
    if params['dataset'] == 'kdd':
        x_train, x_test, y_train, y_test = kdd_encoding(params)
        
    elif params['dataset'] == 'unsw':
        x_train, x_test, y_train, y_test = unsw_encoding(params)

    x_train = np.array(x_train).reshape([-1, x_train.shape[1], 1])
    x_test = np.array(x_test).reshape([-1, x_test.shape[1], 1])
    
    
    return x_train, x_test, y_train, y_test

def print_results(params, model, x_train, x_test, y_train, y_test):
    print('Val loss and acc:')
    print(model.evaluate(x_test, y_test, params['batch_size']))

    y_pred = model.predict(x_test, params['batch_size'])

    print('\nConfusion Matrix:')
    conf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))
    
    print(conf_matrix)

    FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)  # False Positive
    FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)  # False Negative
    TP = np.diag(conf_matrix)  # True Positive
    TN = conf_matrix.sum() - (FP + FN + FP)  # True Negative

    print('\nTPR:')  #True positive rate
    print(TP / (TP + FN))

    print('\nFPR:')  # False Positive Rate
    print(FP / (FP + TN))

    # Cost Matrix
    cost_matrix = [[0, 1, 2, 2, 2],
                   [1, 0, 2, 2, 2],
                   [2, 1, 0, 2, 2],
                   [4, 2, 2, 0, 2],
                   [4, 2, 2, 2, 0]]

    tmp_matrix = np.zeros((5, 5))

    for i in range(5):
        for j in range(5):
            tmp_matrix[i][j] = conf_matrix[i][j] * cost_matrix[i][j]

    
    print('\nCost:')  # The average cost is (total cost / total number of classifications)
    print(tmp_matrix.sum()/conf_matrix.sum())

    print('\nAUC:')  # Average Under Curve
    print(roc_auc_score(y_true=y_test, y_score=y_pred, average=None))

    print('\nPrecision:')  # Probability an instance gets correctly predicted

    print(precision_score(y_true=y_test.argmax(axis=1),y_pred=y_pred.argmax(axis=1), average=None))
